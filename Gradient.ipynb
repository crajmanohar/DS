{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Gradient Desent </h3>\n",
    "<h4>How Gradient Works</h4>\n",
    "1)Gradeant alogoritam Gradent desent algoritham is one optimizer\n",
    "        \n",
    "        It is an istrument totune coefficients.\n",
    "       Coefficient:\n",
    " Coefficient:\n",
    "  Coefficients will construct relationship between input features and labels \n",
    "\n",
    "2) Gradient acts as compass.\n",
    "\tAlways gradient target down fall of loss/cost function.\n",
    "Two types of lose functions \n",
    "\tMSE (mean square error)\n",
    "\t\tFor all regression problems\n",
    "\tCross entropy  \n",
    "\t\tFor all classification problems \n",
    "3) Initially gradient takes random weights bias ad slope(beta=(00).\n",
    "\n",
    "  \tStep 1: Model applies prediction\n",
    "\t\tY=X.β\n",
    "\tStep 2: Compute loss/cost function value\n",
    "\t\tEX : MSE\n",
    "\tStep 3: Gradient Applies derivatives.\n",
    "\t\tTrans(X).(Y-Ycap)/N\n",
    "\t\tGradient produces adjustable which represented by Δ(delta) \n",
    "\tStep4: This delta should be adjusted to old weights with learning rate\n",
    "\t\tβ = β + α(Δ)   \n",
    "\t\tα (Alpha ) is learning rate this should be between 0.04 to 0.06\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =np.c_[np.arange(5)+1]\n",
    "ones=np.ones(5)\n",
    "X=np.c_[ones,x]\n",
    "y=[3,5,7,11,14]\n",
    "Y=np.c_[y]\n",
    "beta=np.c_[np.zeros(X.shape[1])]\n",
    "print(X)\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,b):\n",
    "    return x.dot(b)\n",
    "\n",
    "def mse(y,ycap):\n",
    "    return ((y-ycap)**2).mean()\n",
    "\n",
    "def derivative(x,y,b):\n",
    "    ycap=predict(x,b)\n",
    "    return(x.T.dot(y-ycap))/ y.size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelFit(x,y,itr,alpha,cov=0.0000001):\n",
    "    beta=np.c_[np.zeros(X.shape[1])]\n",
    "    perr=0\n",
    "    for i in range(itr):\n",
    "        ycap= predict(x,beta)\n",
    "        cerr= mse(y,ycap)\n",
    "        diff=np.abs(cerr-perr)\n",
    "        print(diff)\n",
    "        #cerr +=cerr-perr\n",
    "        if i%50==0:\n",
    "            print(\"Current errot\",cerr ,'at',i+1,'position')\n",
    "        j=0\n",
    "        if diff<=cov:\n",
    "            print('Training Completed',i+1,'Th iteration')\n",
    "            j=1\n",
    "            break\n",
    "            \n",
    "        delta = derivative(x,y,beta)\n",
    "        beta+=alpha*delta\n",
    "        perr=cerr\n",
    "        \n",
    "    if j==0:\n",
    "          print(\"Trinig not completed\")\n",
    "    \n",
    "    return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value=modelFit(X,Y,100000,0.05,0.00000000001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
